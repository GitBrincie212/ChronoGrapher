---
title: Basic Use Of Retries
description: Learn how and when to use basic retries
---

In the previous chapter we have discussed the theory about handling failure and how other solutions
as well as ChronoGrapher approach the problem, we haven't discussed however, how to actually create workflows.

One of the common workflow primitives to encounter are **Retries**, they wrap one and only ``TaskFrame`` with the goal of
constantly retrying as the ``TaskFrame`` fails, til it succeeds or the number of retries have been exhausted.

Let's return to our previous Task like so:
<RenderProgrammingLanguageBased target_name={"Rust"}>
```rust title="src/main.rs" lineNumbers
use chronographer::prelude::*;
use thiserror::Error;

// [!code highlight]
// Install the "reqwest" crate

#[derive(Error, Debug)]
pub enum MyErrors {
    #[error("Request failed via {0}")]
    RequestFailed(#[from] reqwest::Error),

    #[error("Too many requests present in our web page")]
    TooManyRequests,

    #[error("Server error regarding our web page")]
    ServerError,

    #[error("Error with different HTTP status code of \"{0}\"")]
    OtherHttpStatus(reqwest::StatusCode)
}

#[task(interval(2s))]
async fn APIRequestTask(ctx: &TaskContext) -> Result<(), MyErrors> {
    let res = reqwest::get("https://httpbin.org/status/200,429,500").await?;

    // For demonstration purposes
    println!("Website responded with {}", res.status());

    // In real code, you would provide more rich errors
    match res.status() {
        200 => Ok(()),
        429 => Err(MyErrors::TooManyRequests),
        500 => Err(MyErrors::ServerError),
        _ => Err(MyErrors::OtherHttpStatus(res.status())),
    }
}

#[chronographer::main]
async fn main(scheduler: DefaultScheduler<MyErrors>) {
    let task_inst = APIRequestTask::instance();
    let _ = scheduler.schedule(task_inst).await;
}
```
</RenderProgrammingLanguageBased>
We have filled the ``MyErrors`` enum with our own errors which we expect, as well as making a Task that does an API
request to some service (in our case ``httpbin`` for demonstrative purposes).

While in typical API requests we expect more status codes which we have to handle gracefully, in our case we expect only
three, those being ``200`` for success, ``429`` for too many requests and ``500`` for a server error.

In real systems these failures arenâ€™t truly random. They usually depend on load, rate limits, outages, or network
issues, but from the client side they may appear so.

Keep in mind this code is here for demonstrative purposes, the idea is to get a grasp on how approximately things are
handled in the real-world when it comes to using ChronoGrapher.

Running the above code yields us something similar to:
```zsh title="terminal"
# 1st run of Task (after 2 total seconds)
[DEBUG] Website responded with 200

# 2nd run of Task (after 4 total seconds)
Website responded with 429

# [!code --]
# ERROR LEAKED THROUGH, CAUSING:
# [!code --]
Scheduler engine received an error for Task with identifier (...):
# [!code --]
    Too many requests present in our web page

# <...>
```

You may notice how the error is leaking through. With the DefaultScheduler, an error causes the task to be terminated, i.e.
Removed and never scheduled again.

However, by requesting, we may encounter errors such as (but not limited to):
- 500: Server error in the website
- 429: Too many requests

These types of errors aren't part of our control, they may be temporary such as ``429`` and then later disappear.
To fix this we can add retries, which re-attempt requests once we hit an error:

<RenderProgrammingLanguageBased target_name={"Rust"}>
```rust title="src/main.rs" lineNumbers=4
#[task(interval(2s))]
// [!code ++]
#[workflow(retry(3))]
async fn APIRequestTask(ctx: &TaskContext) -> Result<(), MyErrors> {
    // ...Same code as before... //
}
```
</RenderProgrammingLanguageBased>

The code retries the request up to 3 times, meaning 4 total attempts including the initial one. Before either
it succeeds or always hit an error, try tweaking the number of retries and see how it changes.

Re-running our code, we may notice a difference:
```zsh title="terminal"
# 1st run of Task (after 2 total seconds)
(Attempt: 0/3) Website responded with 200

# 2nd run of Task (after ~4 total seconds)
(Attempt: 0/3) Website responded with 429
(Attempt: 1/3) Website responded with 500
(Attempt: 2/3) Website responded with 200

# 3rd run of Task (after ~6 total seconds)
(Attempt: 0/3) Website responded with 500
(Attempt: 1/3) Website responded with 429
(Attempt: 2/3) Website responded with 500
(Attempt: 3/3) Website responded with 500

# [!code --]
# ERROR LEAKED THROUGH, CAUSING:
# [!code --]
Scheduler engine received an error for Task with identifier (...):
# [!code --]
    Server error regarding our web page

# <...>
```
**Note:** The attempts (i.e. ``(Attempt X/3)``) are for visual purposes, they show which attempt we are on. The 0th
attempt is when our code runs normally, above zero is when retries occur. It should be noted that 0/3 is the initial
attempt and the rest are from the retry attempt.

Notice the multiple debugs for each run? This means our Task is being retried, though in our case, we configured retries to
happen immediately. To fix this, we can declare a delay per retry like so:
<RenderProgrammingLanguageBased target_name={"Rust"}>
```rust title="src/main.rs" lineNumbers=4
#[task(interval(2s))]
// [!code ++]
#[workflow(retry(3, 2s))]
async fn APIRequestTask(ctx: &TaskContext) -> Result<(), MyErrors> {
    // ...Same code as before... //
}
```
</RenderProgrammingLanguageBased>
> **Note:** the ``2s`` argument is syntax sugar for the following expression:
> ```rust
> std::time::Duration::from_secs(2)
> ```
> It isn't restricted to just seconds, with ``y`` you can declare years, ``M`` for months, ``w`` for weeks,
> ``d`` for days, ``h`` for hours, ``m`` for minutes and even ``ms`` for milliseconds.

With this modification, each retry waits around for 2 total seconds. Tweaking the delay results in faster/slower
retries, depending on the task itself, it might be better to have slower retries over faster ones.

In our case however, 2 seconds is just enough time to follow with another request to our service.

Now running our code again, we notice:
```zsh title="terminal"
# 1st run of Task (after 2 total seconds)
(Attempt: 0/3) Website responded with 200 # Initial Attempt

# 2nd run of Task (after ~4 total seconds)
(Attempt: 0/3) Website responded with 429
(Attempt: 1/3) Website responded with 500 # AFTER 2 SECONDS
(Attempt: 2/3) Website responded with 200 # AFTER 2 SECONDS

# 3rd run of Task (after ~10 total seconds)
(Attempt: 0/3) Website responded with 500
(Attempt: 1/3) Website responded with 429 # AFTER 2 SECONDS
(Attempt: 2/3) Website responded with 500 # AFTER 2 SECONDS
(Attempt: 3/3) Website responded with 500 # AFTER 2 SECONDS

# [!code --]
# ERROR LEAKED THROUGH, CAUSING:
# [!code --]
Scheduler engine received an error for Task with identifier (...):
# [!code --]
    Server error regarding our web page

# <...>
```

<Callout type={"idea"} title={"Pro Tip: Naming Workflow Primitive Arguments"}>
Instead of just dropping values to the arguments, we can name them like so:
<RenderProgrammingLanguageBased target_name={"Rust"}>
    ```rust
    #[workflow(retry(max = 3, delay = 2s))]
    ```
</RenderProgrammingLanguageBased>

You can even mix them up. <Highlight color={"error"}>HOWEVER</Highlight>, named arguments must come after positional arguments:
<RenderProgrammingLanguageBased target_name={"Rust"}>
    ```rust
    #[workflow(retry(3, delay = 2s))]
    ```
</RenderProgrammingLanguageBased>
</Callout>

Generally retries should be used when tasks may fail due to external conditions. We have touched on
API requests as a practical example, but retries can also be used in database queries and in other tasks.

Retries are one of the many workflow primitives which ChronoGrapher has in store. In the next chapter we will be analyzing
fallbacks, and how to combine them.

> TL;DR. Retries allow for re-attempting of a workflow part til the number of retries is exhausted, or it succeeds. They should
be used to remedy 'transient' errors, you can control the number of retry attempts and the delay in-between.