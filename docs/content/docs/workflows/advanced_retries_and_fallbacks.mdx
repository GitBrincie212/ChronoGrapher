---
title: Advanced Retries & Fallbacks
description: Learn more patterns and abilities in-depth about retries and fallbacks
---

In the previous chapter, we saw new workflow primitives, more specifically ``timeout`` and ``delay``. For this chapter,
however, we will take a step back to retries, fallbacks and discuss advanced patterns and usages.

# Advanced Retries
So far we have been discussing *two\** out of the three parameters that retry offers. The asterisk on the two
is on purpose, we have discussed semi the second feature, for simplicity we haven't given it enough justice.

However, now is the time to talk about them, by starting to reframe the second parameter, being delays per retry.
Currently, we briefly looked over them and saw they have a constant duration per retry.

In reality, we have been using an alias (syntax sugar) to cover the complexity, the duration can depend on the number of
retries, the system in question that makes it possible are **Backoff Strategies**.

In layman's terms, a backoff strategy is a function accepting the retry number (the input), with this along with
internal state it computes and spits out a duration (the delay).

The syntactic sugar of ``delay = 2s`` or in positional ``2s``, translates more roughly to ``backoff = constant(2s)``
or in positional ``constant(2s)``. This in of itself was a backoff strategy, the most basic of all.

Which is the reason we used the syntactic sugar, as its easier to write out the duration than writing always a constant
block.

Now with ``constant`` out of the picture, we can discuss more of the dynamic backoff strategies such as ``linear``.
Reverting back our example from before (without timeouts, fallbacks and delays), we can improve it slightly via:
<RenderProgrammingLanguageBased target_name={"Rust"}>
```rust title="src/main.rs" lineNumbers=4
#[task(interval(2s))]
#[workflow(
    retry(3, linear(1s, 500ms, 2s))
    //  OPTIONAL ARGUMENT      ^^^^
)]
async fn api_request_task(ctx: &TaskContext) -> Result<(), TaskError> {
    // ...Same code as before... //
}
```
</RenderProgrammingLanguageBased>
The difference from before is how now every time a retry happens, the delay in-between is incremented by 500ms (starting
from 2 seconds), while capping at 3.5 seconds as a bound.

Try to remove the ``2s``, notice how it grows indefinitely? Now increase ``500ms`` or the ``1s`` to something higher,
what you notice?

Using ``linear`` is useful for basic setups where delays shouldn't be constant, however, while ``linear`` is a better step
towards non-constant delay, for API requests however, it's more idiomatic to use ``exponential``.
<RenderProgrammingLanguageBased target_name={"Rust"}>
```rust title="src/main.rs" lineNumbers=4
#[task(interval(2s))]
#[workflow(
    retry(3, exponential(2, 5s))
    //  OPTIONAL ARGUMENT   ^^
)]
async fn api_request_task(ctx: &TaskContext) -> Result<(), TaskError> {
    // ...Same code as before... //
}
    ```
</RenderProgrammingLanguageBased>
In our example, duration is calculated via ``n = 2^x`` where ``n`` is the delay we get back and ``x`` are the number
of retries. Try changing the base from 2 to 3 and notice how much quicker it grows.

Perhaps remove ``5s`` entirely. Notice how its completely uncapped?

Generally when it comes to choosing which backoff strategy to use, in most cases where delay is constant the ``constant``
backoff strategy is most preferred, ``linear`` for friendlier increasing-delays than ``exponential``.

``exponential`` for ever-increasing exponentiation delays and ``jitter`` used with another backoff strategy for
randomness in the delays.

# Advanced Fallbacks
Currently, with simple fallbacks (where we declared only one fallback), everything is restricted to one ``TaskFrame``.
However, life shouldn't be hard, as such **Multi-Fallbacks** come in the full picture.

Consider this example:
<RenderProgrammingLanguageBased target_name={"Rust"}>
```rust title="src/main.rs" lineNumbers=4
#[derive(Debug)]
struct ServerError;

#[derive(Debug)]
struct ResourceNotFound404;

#[derive(Debug)]
struct ResourceNotFound;

#[taskframe]
async fn my_task_fallback(ctx: &TaskContext) -> Result<(), TaskError> {
    if let Some(err) = ctx.get_shared::<TaskError>() {
        match err {
            other => Err(other)
        }
    }
    panic!("my_task_fallback isn't used as a fallback");
}

#[task(interval(6s))]
#[workflow(
    fallback(my_task_fallback)
)]
async fn my_task(ctx: &TaskContext) -> Result<(), TaskError> {
    // ...
}
```
</RenderProgrammingLanguageBased>

With simple fallbacks, the fallback has to manage every different error that comes from our business logic (and workflow,
though for simplicity not included).

While one can make a monolithic function that tries to manage all errors, depending on the action performed by the business logic,
different ways are required to handle the "same looking error".

This is where the **Multi-Fallbacks** idea comes in play, instead of one, we can split the monolithic fallback to multiple
smaller, single-purpose and reusable fallbacks.

To achieve this let's rewrite our example like so:
<RenderProgrammingLanguageBased target_name={"Rust"}>
```rust title="src/main.rs" lineNumbers=4
#[taskframe]
async fn my_task_error1_fallback(ctx: &TaskContext) -> Result<(), TaskError> {
    // ...
}

#[task(interval(6s))]
#[workflow(
    fallback(my_task_fallback)
)]
async fn my_task(ctx: &TaskContext) -> Result<(), TaskError> {
    // ...
}
    ```
</RenderProgrammingLanguageBased>